{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atosh502/smarter-healthcare/blob/master/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WgOqnxPrZ-y",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# execute this block when running on google colab\n",
        "!apt-get install openjdk-8-jdk\n",
        "!wget https://www-us.apache.org/dist/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz \n",
        "!tar xf spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!pip install findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.3-bin-hadoop2.7\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# uncomment the line below if you are running the code on a new drive\n",
        "# !git clone https://github.com/atosh502/smarter-healthcare.git\n",
        "%cd /content/drive/My Drive/smarter-healthcare"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBSI8o76MHzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkContext, SparkConf\n",
        "sc = SparkContext(master=\"local[4]\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKeexGAFJFQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.classification import LogisticRegression, LogisticRegressionTrainingSummary, LogisticRegressionModel, LogisticRegressionSummary\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vectors\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYA82MdxIWLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(dataset, feature_cols, label):\n",
        "  assembler = VectorAssembler(inputCols=feature_cols,outputCol='features')\n",
        "  data = assembler.transform(dataset)\n",
        "  return data.select(label,\"features\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMxvB8MnGdbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_and_predict(training, testing):\n",
        "  lr = LogisticRegression(maxIter=10,regParam=.1,featuresCol=\"features\",labelCol=\"readmitted\")\n",
        "  model = lr.fit(training)\n",
        "  return model.transform(testing)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGnd9IH0lv4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(predictions):\n",
        "  correct_predictions = predictions.select(\"*\").where(predictions['readmitted']==predictions['prediction'])\n",
        "  return correct_predictions.count()/predictions.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoq_1ogFpdcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load dataset\n",
        "dataset_path = \"./parquet_files/dataset.parquet\"\n",
        "dataset = spark.read.parquet(dataset_path)\n",
        "full_features = dataset.drop('readmitted').columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRgj-Nmwr0F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine best set of attributes by pruning attributes one by one if it increases classification accuracy\n",
        "# a better alternative would be to use best 10 attributes determined by gini-index (top 10 attributes from decision tree)\n",
        "label = 'readmitted'\n",
        "feature_set = full_features\n",
        "data = prepare_data(dataset, feature_set, label)\n",
        "training, testing = data.randomSplit([.7,.3])\n",
        "predictions = fit_and_predict(training, testing)\n",
        "best_accuracy_till_now = accuracy(predictions)\n",
        "for item in full_features:\n",
        "  temp_feature_set = feature_set.copy()\n",
        "  temp_feature_set.remove(item)\n",
        "  data = prepare_data(dataset, temp_feature_set, label)\n",
        "  training, testing = data.randomSplit([.7,.3])\n",
        "  predictions = fit_and_predict(training, testing)\n",
        "  acc = accuracy(predictions)\n",
        "  if(acc>best_accuracy_till_now):\n",
        "    best_accuracy_till_now = acc\n",
        "    feature_set = temp_feature_set.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMahlg0tLhTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a17e88b4-5bd0-4d90-d0ba-b79785efa3c8"
      },
      "source": [
        "# accuray after pruning\n",
        "print(\"After pruning:\")\n",
        "full_features = dataset.drop('readmitted').columns\n",
        "print(\"length of feature set: \",len(feature_set))\n",
        "print(\"accuracy: \", best_accuracy_till_now)\n",
        "\n",
        "# accuracy before pruning\n",
        "data = prepare_data(dataset, full_features, label)\n",
        "training, testing = data.randomSplit([.7,.3])\n",
        "predictions = fit_and_predict(training, testing)\n",
        "print(\"Before pruning:\")\n",
        "print(\"length of feature set: \", len(full_features))\n",
        "print(\"accuracy: \", accuracy(predictions))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After pruning:\n",
            "length of feature set:  125\n",
            "accuracy:  0.6197092193763163\n",
            "Before pruning:\n",
            "length of feature set:  130\n",
            "accuracy:  0.60213192110534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moPldDSBTR_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94b484ce-2831-4905-89c4-a5519ec564ad"
      },
      "source": [
        "# testing if the classifier performs well when one of the items in the feature set is the label itsef\n",
        "features_with_label = dataset.columns\n",
        "data = prepare_data(dataset,features_with_label, label)\n",
        "training, testing = data.randomSplit([.7, .3])\n",
        "predictions = fit_and_predict(training, testing)\n",
        "print(accuracy(predictions))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9999662936497236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBcRsVngStf0",
        "colab_type": "text"
      },
      "source": [
        "#analysis so far...\n",
        "Logistic regression is a very simple model with a single input and output layer and no hidden layers. From the cell right above we can see that, the model predicts well even in the presence of noise, when one of the attributes perfectly determines the output. However, if there is no perfect correlation, noise largely affects the classification.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/faq/logisticregr-neuralnet/schematic.png\">\n",
        "\n",
        "#next steps\n",
        "1. take only 10 best features determined using gini index. (this features can be obtained from the output of decision-tree classifier) \n",
        "2. use the above used greedy approach to further prune from the 10 best features\n",
        "3. perform significance test on accuracy of present result and the result after performing steps 1 and 2.\n",
        "4. compare with outputs of decision tree and random forest."
      ]
    }
  ]
}